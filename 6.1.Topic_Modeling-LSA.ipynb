{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7VbPW-VLYdL"
   },
   "source": [
    "# 1.LSA 간단 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1725791995553,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "hZEHWsAQLFWR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zpLD7DEL_qk"
   },
   "source": [
    "## 1.DTM 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1725791995553,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "4q2uW5-RLYFK",
    "outputId": "0ee2fc4f-8661-483b-8507-e4a05414ff9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM의 크기(shape) : (4, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.array([[0,0,0,1,0,1,1,0,0],\n",
    "              [0,0,0,1,1,0,1,0,0],\n",
    "              [0,1,1,0,2,0,0,0,0],\n",
    "              [1,0,0,0,0,0,0,1,1]])\n",
    "print('DTM의 크기(shape) :', np.shape(A))\n",
    "display(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM1NoOqzMGNi"
   },
   "source": [
    "## 2.Full SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_matrices = True : U = mxm, VT = nxn 크기로 만들겠다는 의미\n",
    "# full_matrices = False : U 와 V의 크기는 최소한의 크기로 줄이겠다는 의미  ->  메모리와 계산 시간을 절약하기 위함\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEmLHIOHRLWA"
   },
   "source": [
    "- U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(U.shape)\n",
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpjKLYozNzOj"
   },
   "source": [
    "- S\n",
    "- linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아닌 특이값의 리스트를 반환 따라서 다시 대각 행렬로 변환 해주어야 함.\n",
    "- np.diag()는 1차원 array는 각각의 값을 대각 성분으로 가지는 대각 행렬 생성, 2차원은 대각 성분의 값을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.68731789 2.04508425 1.73205081 0.77197992]\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s)\n",
    "print(s.shape)\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.68731789, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 2.04508425, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.73205081, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.77197992]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(s)    # 대각행렬 생성 메서드로 array 를 입력값으로 받아들임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1725791995554,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "orLlrJ3iMegv",
    "outputId": "e9390b2b-51f9-432c-8846-62e5714d98da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "# 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S = np.zeros((4,9))\n",
    "print(S)\n",
    "print()\n",
    "\n",
    "# 특이값을 대각행렬에 삽입\n",
    "S[:4, :4]\n",
    "print(S.round(2))\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3FFI088NxSD"
   },
   "source": [
    "- VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "print(VT.round(2))\n",
    "print(VT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWeCXgwDNVIm"
   },
   "source": [
    "- U X S X VT = A\n",
    "- np.allclose() : 두 배열이 거의 같은지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U, S), VT).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJUns-w_PzeI"
   },
   "source": [
    "## 3.Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1725791995554,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "3z7s2rzKM8mf",
    "outputId": "b7253a62-f837-4d2a-aef7-f2f28af5dad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 특이값 상위 2개만 보존\n",
    "S = S[:2,:2]\n",
    "\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4, 2)\n",
      "[[-2.39751712e-01  7.51083898e-01]\n",
      " [-5.06077194e-01  4.44029376e-01]\n",
      " [-8.28495619e-01 -4.88580485e-01]\n",
      " [-8.78352025e-17 -2.98807451e-17]]\n"
     ]
    }
   ],
   "source": [
    "print(U.shape)\n",
    "U = U[:,:2]\n",
    "print(U.shape)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9)\n",
      "(2, 9)\n",
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(VT.shape)\n",
    "\n",
    "VT = VT[:2, :]\n",
    "print(VT.shape)\n",
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "(4, 9)\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "A_prime = np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))\n",
    "print()\n",
    "print(A.shape)\n",
    "print(A_prime.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OGOrky9xRLI"
   },
   "source": [
    "## 4.sklearn TruncatedSVD 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1725791996877,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "cXXgiqFSmogJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# TruncatedSVD 객체 생성\n",
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42)\n",
    "\n",
    "# 문서-토픽 행렬 생성 UxS\n",
    "lsa_matrix = svd_model.fit_transform(A)\n",
    "\n",
    "# 단어-토픽 행렬 (components_) VT\n",
    "components = svd_model.components_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn4KgUiAq9Q5"
   },
   "source": [
    "- **fit_transform**은 문서-토픽 행렬을 반환. U x S\\\n",
    "      - 행(n_samples): 이 행렬의 각 행은 하나의 문서를 나타냄.\\\n",
    "      - 열(n_components): 이 행렬의 각 열은 하나의 토픽(축소된 차원)을 나타냄.\\\n",
    "      - 각 값: 특정 문서가 특정 토픽에서 얼마나 설명되는지를 나타냄. 값이 클수록 그 문서가 해당 토픽에서 더 잘 설명된다는 의미.\\\n",
    "\n",
    "- **components_**는 토픽-단어 행렬. S x VT\\\n",
    "      - 행(n_components): 토픽을 나타냄.\\\n",
    "      - 열(n_features): 단어를 나타냄.\\\n",
    "      - 각 값: 특정 토픽에서 특정 단어의 가중치(기여도)를 나타냄.\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1725791996877,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "fOFeN4oWpMq5",
    "outputId": "1bf74f96-875b-4c2e-8c4a-bb4c2596f940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA 변환 결과 (문서 x 토픽 행렬):\n",
      "[[ 6.44289063e-01  1.53602985e+00]\n",
      " [ 1.35999029e+00  9.08077483e-01]\n",
      " [ 2.22643109e+00 -9.99188254e-01]\n",
      " [-4.58923455e-16  1.57281088e-16]]\n",
      "LSA 변환 결과 (토픽 x 단어 행렬):\n",
      "[[-1.18279879e-16  3.08298331e-01  3.08298331e-01  2.77536539e-01\n",
      "   8.04917216e-01  8.92159849e-02  2.77536539e-01 -1.70321788e-16\n",
      "  -1.70321788e-16]\n",
      " [-3.54655479e-17 -2.38904821e-01 -2.38904821e-01  5.84383395e-01\n",
      "  -2.60689306e-01  3.67263060e-01  5.84383395e-01  9.63733179e-17\n",
      "   9.63733179e-17]]\n",
      "\n",
      "근사된 행렬 (A_prime):\n",
      "[[-0.   -0.17 -0.17  1.08  0.12  0.62  1.08  0.    0.  ]\n",
      " [-0.    0.2   0.2   0.91  0.86  0.45  0.91 -0.   -0.  ]\n",
      " [-0.    0.93  0.93  0.03  2.05 -0.17  0.03 -0.   -0.  ]\n",
      " [ 0.   -0.   -0.   -0.   -0.    0.   -0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# 출력\n",
    "print(\"LSA 변환 결과 (문서 x 토픽 행렬):\")\n",
    "print(lsa_matrix)\n",
    "\n",
    "print(\"LSA 변환 결과 (토픽 x 단어 행렬):\")\n",
    "print(components)\n",
    "\n",
    "# 원래 행렬 근사\n",
    "A_prime = np.dot(lsa_matrix, components)\n",
    "print(\"\\n근사된 행렬 (A_prime):\")\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prime_df = pd.DataFrame(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za1tU6pNRwMv"
   },
   "source": [
    "# 2.뉴스 데이터를 통한 LSA 분석\n",
    "- 사이킷런에서는 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 뉴스그룹 데이터를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFjz5qIeR8e7"
   },
   "source": [
    "## 1.필요 모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1725791997219,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "rJMMsFpiQca6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l47ST_zR_VI"
   },
   "source": [
    "## 2.데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 수:  11314\n"
     ]
    }
   ],
   "source": [
    "# 18000개의 문서로 이루어진 데이터셋 로그\n",
    "dataset = fetch_20newsgroups(\n",
    "    shuffle = True,                             # 데이터를 섞어서 로드 -> 데이터의 순서가 주는 영향을 방지하기 위함\n",
    "    random_state = 1,\n",
    "    remove = ('headers', 'footers', 'quotes')    # 헤더, 푸터, 인용문 등을 제거 -> 분류작업에 유용하지 않을 가능성이 높은 텍스트 요소 제거\n",
    ")\n",
    "\n",
    "documents = dataset.data\n",
    "print('샘플 수: ', len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\",\n",
       " \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\",\n",
       " \"Although I realize that principle is not one of your strongest\\npoints, I would still like to know why do do not ask any question\\nof this sort about the Arab countries.\\n\\n   If you want to continue this think tank charade of yours, your\\nfixation on Israel must stop.  You might have to start asking the\\nsame sort of questions of Arab countries as well.  You realize it\\nwould not work, as the Arab countries' treatment of Jews over the\\nlast several decades is so bad that your fixation on Israel would\\nbegin to look like the biased attack that it is.\\n\\n   Everyone in this group recognizes that your stupid 'Center for\\nPolicy Research' is nothing more than a fancy name for some bigot\\nwho hates Israel.\",\n",
       " 'Notwithstanding all the legitimate fuss about this proposal, how much\\nof a change is it?  ATT\\'s last product in this area (a) was priced over\\n$1000, as I suspect \\'clipper\\' phones will be; (b) came to the customer \\nwith the key automatically preregistered with government authorities. Thus,\\naside from attempting to further legitimize and solidify the fed\\'s posture,\\nClipper seems to be \"more of the same\", rather than a new direction.\\n   Yes, technology will eventually drive the cost down and thereby promote\\nmore widespread use- but at present, the man on the street is not going\\nto purchase a $1000 crypto telephone, especially when the guy on the other\\nend probably doesn\\'t have one anyway.  Am I missing something?\\n   The real question is what the gov will do in a year or two when air-\\ntight voice privacy on a phone line is as close as your nearest pc.  That\\nhas got to a problematic scenario for them, even if the extent of usage\\nnever surpasses the \\'underground\\' stature of PGP.',\n",
       " \"Well, I will have to change the scoring on my playoff pool.  Unfortunately\\nI don't have time right now, but I will certainly post the new scoring\\nrules by tomorrow.  Does it matter?  No, you'll enter anyway!!!  Good!\\n\\n--\\n    Keith Keller\\t\\t\\t\\tLET'S GO RANGERS!!!!!\\n\\t\\t\\t\\t\\t\\tLET'S GO QUAKERS!!!!!\\n\\tkkeller@mail.sas.upenn.edu\\t\\tIVY LEAGUE CHAMPS!!!!\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "카테고리 수 :  20\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 토픽 확인\n",
    "\n",
    "print(dataset.target_names)\n",
    "print('카테고리 수 : ', len(dataset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgTqL3PFU8mo"
   },
   "source": [
    "## 3.데이터 전처리\n",
    "  1. 대문자->소문자\n",
    "  2. 구두점, 숫자, 특수 문자 제거\n",
    "  3. 짧은 단어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwqo-CkBVyVR"
   },
   "source": [
    "- [^a-zA-Z] : 영문자를 제외한 모든 문자\n",
    "- regrex=True : 함수에서 이 패턴을 정규 표현식으로 처리\n",
    "- ' '.join([w for w in x.split() if len(w)>3]) : 데이터를 순회하면서 공백으로 단어를 나누고 길이가 3이상인 단어들을 리스트로 반환하고 join 함수를 통해서 한 줄의 텍스트로 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents\n",
       "0  Well i'm not sure about the story nad it did s...\n",
       "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2  Although I realize that principle is not one o...\n",
       "3  Notwithstanding all the legitimate fuss about ...\n",
       "4  Well, I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame({'documents': documents})\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 5718,
     "status": "ok",
     "timestamp": 1725792007485,
     "user": {
      "displayName": "김지성",
      "userId": "08089280915681010656"
     },
     "user_tz": -540
    },
    "id": "eHGOjgOXSGDE"
   },
   "outputs": [],
   "source": [
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['documents'].str.replace('[^a-zA-Z]', \" \", regex = True)\n",
    "\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in  x.split() if len(w) > 3]))\n",
    "\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>clean_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "      <td>well sure about story seem biased what disagre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "      <td>yeah expect people read actually accept hard a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "      <td>although realize that principle your strongest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "      <td>notwithstanding legitimate fuss about this pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "      <td>well will have change scoring playoff pool unf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n \\nI read somewhere, I think in Morton Smit...</td>\n",
       "      <td>read somewhere think morton smith jesus magici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nOk.  I have a record that shows a IIsi with ...</td>\n",
       "      <td>have record that shows iisi with without cache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'...</td>\n",
       "      <td>sounds like wishful guessing called what mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nobody is saying that you shouldn't be allowe...</td>\n",
       "      <td>nobody saying that shouldn allowed just force ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n  I was wondering if anyone can shed any lig...</td>\n",
       "      <td>wondering anyone shed light just that these el...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  Well i'm not sure about the story nad it did s...   \n",
       "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...   \n",
       "2  Although I realize that principle is not one o...   \n",
       "3  Notwithstanding all the legitimate fuss about ...   \n",
       "4  Well, I will have to change the scoring on my ...   \n",
       "5   \\n \\nI read somewhere, I think in Morton Smit...   \n",
       "6  \\nOk.  I have a record that shows a IIsi with ...   \n",
       "7  \\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'...   \n",
       "8   Nobody is saying that you shouldn't be allowe...   \n",
       "9  \\n  I was wondering if anyone can shed any lig...   \n",
       "\n",
       "                                           clean_doc  \n",
       "0  well sure about story seem biased what disagre...  \n",
       "1  yeah expect people read actually accept hard a...  \n",
       "2  although realize that principle your strongest...  \n",
       "3  notwithstanding legitimate fuss about this pro...  \n",
       "4  well will have change scoring playoff pool unf...  \n",
       "5  read somewhere think morton smith jesus magici...  \n",
       "6  have record that shows iisi with without cache...  \n",
       "7  sounds like wishful guessing called what mean ...  \n",
       "8  nobody saying that shouldn allowed just force ...  \n",
       "9  wondering anyone shed light just that these el...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBY3bmkSWrPb"
   },
   "source": [
    "## 4.TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DF-gsokljXM"
   },
   "source": [
    "- stop_words='english' : 불용어 사전, sklearn에서 제공하는 기본 영어 불용어 리스트\n",
    "- max_features=1000 : 상위 1000개의 단어만을 보존\n",
    "- max_df=0.5 : 너무 자주 등장하는 경우 해당 단어를 무시. 50% 이상 나타나는 단어는 무시\n",
    "- smooth_idf=True : IDF 점수 계산 시, smoothing을 적용.\n",
    "  - 스무딩은 IDF 계산에서 모든 문서에 1을 더하는 방식으로, IDF 값이 0이 되는 것을 방지. 즉 적절한 IDF 값을 가지게 하고 안정적인 결과를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                        max_features = 1000,\n",
    "                        max_df = 0.5,\n",
    "                        smooth_idf = True,\n",
    "                        )\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXIuR1xPXDam"
   },
   "source": [
    "## 5.LSA를 통한 토픽 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model = TruncatedSVD(n_components = 20, algorithm='randomized', n_iter=100, random_state=10)\n",
    "svd_model.fit(X)        #UxS\n",
    "len(svd_model.components_)      #SxVT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01409818,  0.04787982,  0.02051048, ...,  0.07483329,\n",
       "         0.01377606,  0.01712888],\n",
       "       [-0.00521437,  0.01742255, -0.01542793, ..., -0.06266609,\n",
       "        -0.01075043, -0.01888594],\n",
       "       [ 0.00243598, -0.00142246, -0.01848973, ...,  0.05823359,\n",
       "         0.02412148,  0.02038499],\n",
       "       ...,\n",
       "       [ 0.00746824, -0.00689738, -0.00963879, ..., -0.03316437,\n",
       "        -0.00649624, -0.0002525 ],\n",
       "       [ 0.00352545,  0.01029423, -0.01284824, ...,  0.01336511,\n",
       "        -0.01588696, -0.00127575],\n",
       "       [-0.00221751,  0.00855739,  0.0062343 , ..., -0.0511237 ,\n",
       "        -0.00794476, -0.00491316]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lReTBAohdVv_"
   },
   "source": [
    "- argsort() : 배열의 인덱스를 정렬된 순서로 반환 [3,1,2] -> [1,2,0] (오름차순 정렬)\n",
    "- [::-1][:5] : 역순으로 정렬 후 5개의 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax :  [[0 2 4 1 3]]\n",
      "[3 1 4 2 0]\n"
     ]
    }
   ],
   "source": [
    "example_array = np.array([[0.1, 0.4, 0.2, 0.9, 0.3]])\n",
    "print('argmax : ', example_array.argsort())\n",
    "\n",
    "sorted_indices = example_array.argsort()[0][::-1][:5]\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2zv_jBUD6mi"
   },
   "source": [
    "- 주제0번에 대한 단어별 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01409818, 0.04787982, 0.02051048, 0.02933549, 0.01732167,\n",
       "       0.01227351, 0.01648381, 0.01181282, 0.01084788, 0.0593574 ,\n",
       "       0.01055266, 0.0111863 , 0.00867278, 0.03419897, 0.01132049,\n",
       "       0.0401397 , 0.0177775 , 0.00850201, 0.03508718, 0.0158544 ,\n",
       "       0.02076485, 0.01292826, 0.01060273, 0.01168965, 0.01392965,\n",
       "       0.02813562, 0.0110224 , 0.00927105, 0.00607689, 0.0090752 ,\n",
       "       0.03507546, 0.01364729, 0.01940152, 0.04266487, 0.01638954,\n",
       "       0.0120186 , 0.01376949, 0.02842646, 0.02492808, 0.01559292,\n",
       "       0.01259682, 0.021828  , 0.03209353, 0.01136994, 0.01236091,\n",
       "       0.01826516, 0.01198612, 0.00833366, 0.03061078, 0.01221436,\n",
       "       0.02441905, 0.02483554, 0.01177919, 0.00769201, 0.0165582 ,\n",
       "       0.01614453, 0.01055487, 0.01213478, 0.03688943, 0.01293101,\n",
       "       0.02388438, 0.02126642, 0.02266981, 0.01389217, 0.01078975,\n",
       "       0.01070881, 0.01389446, 0.0098783 , 0.01064283, 0.01166813,\n",
       "       0.05015364, 0.01938976, 0.01583951, 0.04028201, 0.01072811,\n",
       "       0.01719875, 0.02045526, 0.03970562, 0.01404409, 0.01610265,\n",
       "       0.01334269, 0.01173088, 0.01054992, 0.01465089, 0.01299643,\n",
       "       0.07890412, 0.05921976, 0.07381847, 0.03534568, 0.03939203,\n",
       "       0.01053376, 0.01309968, 0.02305592, 0.01030658, 0.01542287,\n",
       "       0.01202174, 0.03034135, 0.02501139, 0.04076944, 0.02173604,\n",
       "       0.01020105, 0.02519626, 0.01590821, 0.01619363, 0.01264306,\n",
       "       0.02037551, 0.01619681, 0.02072355, 0.02181794, 0.01703492,\n",
       "       0.01136249, 0.04733823, 0.01273743, 0.01268688, 0.03317941,\n",
       "       0.01387891, 0.05987849, 0.02406369, 0.02948062, 0.01575537,\n",
       "       0.0260114 , 0.06136791, 0.01813905, 0.0306592 , 0.01952811,\n",
       "       0.02648471, 0.03125562, 0.01890933, 0.03605516, 0.01639754,\n",
       "       0.01339521, 0.00234846, 0.00950773, 0.01845606, 0.02984402,\n",
       "       0.01260772, 0.01513099, 0.02906934, 0.04447801, 0.02028458,\n",
       "       0.01854462, 0.02558632, 0.03455694, 0.01729958, 0.02829264,\n",
       "       0.02963493, 0.01371102, 0.02085335, 0.01308275, 0.02912228,\n",
       "       0.01522802, 0.01646788, 0.02333671, 0.01620218, 0.02149877,\n",
       "       0.0268029 , 0.01442268, 0.02130791, 0.03458222, 0.03068452,\n",
       "       0.00988132, 0.0140223 , 0.05988254, 0.03430668, 0.02103581,\n",
       "       0.01489532, 0.01492139, 0.01738768, 0.01294806, 0.0064907 ,\n",
       "       0.02410219, 0.01161971, 0.01109083, 0.0115886 , 0.0144098 ,\n",
       "       0.02576612, 0.01715518, 0.01854868, 0.04551206, 0.00952724,\n",
       "       0.02340311, 0.00910958, 0.01148385, 0.0274488 , 0.01824109,\n",
       "       0.01501736, 0.02214146, 0.00948673, 0.01370945, 0.01239539,\n",
       "       0.00408314, 0.03644602, 0.02097184, 0.01280248, 0.02657754,\n",
       "       0.02818252, 0.03125256, 0.01377367, 0.02384632, 0.01287629,\n",
       "       0.01182569, 0.02562072, 0.03200903, 0.05816872, 0.01983659,\n",
       "       0.01450363, 0.01799998, 0.01438758, 0.01852764, 0.01291278,\n",
       "       0.01250224, 0.03522814, 0.02028906, 0.05015332, 0.01597354,\n",
       "       0.01655291, 0.02737212, 0.03470089, 0.02260643, 0.0294719 ,\n",
       "       0.02304121, 0.01581329, 0.00955272, 0.00725122, 0.019312  ,\n",
       "       0.00962337, 0.02544207, 0.0120104 , 0.01054993, 0.00962551,\n",
       "       0.01906788, 0.01596936, 0.01726693, 0.00936235, 0.00858426,\n",
       "       0.01461813, 0.0179247 , 0.01324347, 0.06724776, 0.01201363,\n",
       "       0.03096392, 0.0529709 , 0.01581768, 0.01438218, 0.01140465,\n",
       "       0.01605537, 0.01449316, 0.02149967, 0.0149166 , 0.03583293,\n",
       "       0.01302515, 0.02668941, 0.00923289, 0.0140731 , 0.0143416 ,\n",
       "       0.15335612, 0.07181041, 0.04614263, 0.01369173, 0.01415617,\n",
       "       0.0214014 , 0.01161519, 0.0714603 , 0.030753  , 0.02788009,\n",
       "       0.02298284, 0.01652681, 0.01367794, 0.01269133, 0.01318845,\n",
       "       0.02209263, 0.0223198 , 0.01864259, 0.01241507, 0.02605742,\n",
       "       0.01043495, 0.02077665, 0.01277214, 0.01108413, 0.01018162,\n",
       "       0.0457216 , 0.02643261, 0.01097536, 0.02271284, 0.01440161,\n",
       "       0.00639221, 0.01145518, 0.01495439, 0.02052737, 0.01014174,\n",
       "       0.01227089, 0.02610365, 0.01372478, 0.01330701, 0.03444828,\n",
       "       0.02874971, 0.03939474, 0.01737533, 0.02213407, 0.01329846,\n",
       "       0.01394035, 0.02139372, 0.01273831, 0.01443547, 0.02843541,\n",
       "       0.01850791, 0.0081604 , 0.01897392, 0.02341313, 0.05163241,\n",
       "       0.01549058, 0.02493717, 0.01389945, 0.01114088, 0.01743677,\n",
       "       0.02929955, 0.01707499, 0.01447457, 0.01072228, 0.01778776,\n",
       "       0.03411856, 0.01442345, 0.02063091, 0.05553355, 0.04281264,\n",
       "       0.01307833, 0.01866563, 0.0326407 , 0.01058627, 0.01688638,\n",
       "       0.02268118, 0.01810843, 0.03627042, 0.00968134, 0.00910895,\n",
       "       0.02108415, 0.02185577, 0.0150246 , 0.01951727, 0.0183369 ,\n",
       "       0.03613337, 0.01374381, 0.02727806, 0.01478078, 0.00978502,\n",
       "       0.01431961, 0.00934193, 0.01956852, 0.05735148, 0.03962902,\n",
       "       0.01745127, 0.03074665, 0.01503349, 0.0072904 , 0.01071819,\n",
       "       0.02545292, 0.04783332, 0.03505131, 0.01612847, 0.01439492,\n",
       "       0.01385148, 0.00917678, 0.02846083, 0.07872309, 0.01586357,\n",
       "       0.14379843, 0.06215069, 0.03462261, 0.05617824, 0.01881066,\n",
       "       0.01140394, 0.0182316 , 0.04776096, 0.01803524, 0.03759454,\n",
       "       0.02434987, 0.01843887, 0.02047001, 0.03409726, 0.01364962,\n",
       "       0.01298777, 0.02446789, 0.02305823, 0.0174308 , 0.01736906,\n",
       "       0.05221929, 0.0272167 , 0.02928299, 0.0470423 , 0.02312929,\n",
       "       0.01496785, 0.02912637, 0.05026885, 0.01166766, 0.02673943,\n",
       "       0.01944372, 0.07414082, 0.04726995, 0.01809069, 0.0245539 ,\n",
       "       0.02458891, 0.01885189, 0.01057402, 0.03471435, 0.03855205,\n",
       "       0.01407761, 0.01997011, 0.02956873, 0.04694696, 0.02082812,\n",
       "       0.02429573, 0.0116787 , 0.01722494, 0.02792055, 0.02393543,\n",
       "       0.01704669, 0.01820487, 0.02363046, 0.01236353, 0.0082113 ,\n",
       "       0.01464085, 0.04227749, 0.05939609, 0.01596259, 0.01712185,\n",
       "       0.02038879, 0.0302524 , 0.00748505, 0.01391841, 0.01118785,\n",
       "       0.04441341, 0.02792653, 0.01428786, 0.01898367, 0.01095537,\n",
       "       0.02134116, 0.01895232, 0.02907078, 0.01995115, 0.02850727,\n",
       "       0.01279163, 0.01190218, 0.04700022, 0.01962944, 0.02525243,\n",
       "       0.01061243, 0.02929859, 0.00381891, 0.20886722, 0.0123067 ,\n",
       "       0.01561753, 0.02364873, 0.02068013, 0.02045741, 0.01303758,\n",
       "       0.04243707, 0.01144179, 0.01714504, 0.19348726, 0.01905126,\n",
       "       0.02742818, 0.02362655, 0.01410489, 0.01615705, 0.0140705 ,\n",
       "       0.03196144, 0.01482173, 0.02970829, 0.01384932, 0.01281598,\n",
       "       0.02051754, 0.01330424, 0.02287181, 0.01840298, 0.01938575,\n",
       "       0.03920332, 0.01900943, 0.01324948, 0.02650948, 0.01529882,\n",
       "       0.00969705, 0.04895618, 0.02518351, 0.2046869 , 0.02815664,\n",
       "       0.01470619, 0.04674244, 0.0224682 , 0.04605805, 0.06567454,\n",
       "       0.03128002, 0.01347189, 0.01773377, 0.03591491, 0.01635041,\n",
       "       0.0651054 , 0.02127179, 0.06448103, 0.02025952, 0.05732678,\n",
       "       0.02858382, 0.01459993, 0.02075561, 0.01969895, 0.03278207,\n",
       "       0.01404704, 0.00803461, 0.03237159, 0.01651559, 0.01353417,\n",
       "       0.07275799, 0.01099902, 0.01796918, 0.02374907, 0.01437544,\n",
       "       0.10460603, 0.03832896, 0.02978454, 0.01797728, 0.02004559,\n",
       "       0.00725821, 0.02105459, 0.01990333, 0.01259683, 0.00964322,\n",
       "       0.01126833, 0.03198525, 0.00710635, 0.05411777, 0.04977002,\n",
       "       0.01481573, 0.03641265, 0.0174177 , 0.01509704, 0.01304189,\n",
       "       0.01477221, 0.03936474, 0.01629834, 0.02315303, 0.02909846,\n",
       "       0.00930946, 0.01344178, 0.01309147, 0.01533907, 0.02103227,\n",
       "       0.01776541, 0.01882218, 0.01640482, 0.03271912, 0.015169  ,\n",
       "       0.00798184, 0.00703484, 0.02574569, 0.02531677, 0.01407817,\n",
       "       0.02266219, 0.01267638, 0.03968965, 0.03442947, 0.01364142,\n",
       "       0.02476192, 0.01228036, 0.01686091, 0.01315438, 0.01663802,\n",
       "       0.01966962, 0.01136422, 0.01061812, 0.00830699, 0.01299921,\n",
       "       0.02149014, 0.02230216, 0.01298489, 0.01551339, 0.02078439,\n",
       "       0.01688571, 0.09708718, 0.01909302, 0.02347813, 0.01825306,\n",
       "       0.03491926, 0.02077002, 0.03534277, 0.02237465, 0.02061301,\n",
       "       0.01115834, 0.03290436, 0.00484668, 0.05633588, 0.02454859,\n",
       "       0.012616  , 0.01186083, 0.01633866, 0.01853425, 0.03027232,\n",
       "       0.00994268, 0.01744293, 0.00988978, 0.02611078, 0.02635796,\n",
       "       0.00874745, 0.02165291, 0.02039204, 0.01427852, 0.01085491,\n",
       "       0.01040014, 0.04276838, 0.01483927, 0.03614481, 0.01975037,\n",
       "       0.01809377, 0.02320783, 0.01157128, 0.01358856, 0.01438454,\n",
       "       0.01626658, 0.0201713 , 0.01216347, 0.02146663, 0.01435025,\n",
       "       0.01281718, 0.00880075, 0.02352849, 0.0113199 , 0.01957501,\n",
       "       0.01574594, 0.1831816 , 0.01701422, 0.02180947, 0.01640667,\n",
       "       0.04264925, 0.0206429 , 0.01152391, 0.03535605, 0.01192799,\n",
       "       0.01595985, 0.01424875, 0.01080517, 0.04129649, 0.01766436,\n",
       "       0.01446683, 0.03654797, 0.01498581, 0.02201689, 0.02847342,\n",
       "       0.01637739, 0.02363921, 0.07223408, 0.02126014, 0.02357633,\n",
       "       0.01238519, 0.01548444, 0.0143801 , 0.01496377, 0.01903587,\n",
       "       0.02270835, 0.05001268, 0.0164829 , 0.05690841, 0.02350063,\n",
       "       0.03017449, 0.01516793, 0.00859917, 0.05844047, 0.01261595,\n",
       "       0.0157439 , 0.01875653, 0.01766782, 0.04396188, 0.01227098,\n",
       "       0.01320897, 0.04165885, 0.01303819, 0.0179611 , 0.0125241 ,\n",
       "       0.01772059, 0.06493699, 0.09267923, 0.04841238, 0.01828802,\n",
       "       0.00700923, 0.0109777 , 0.01837894, 0.01296403, 0.05764078,\n",
       "       0.01053188, 0.02363222, 0.01531192, 0.01216678, 0.01158386,\n",
       "       0.01344327, 0.02319363, 0.01000433, 0.00788354, 0.03952908,\n",
       "       0.01055161, 0.0170642 , 0.02062244, 0.0661096 , 0.03449492,\n",
       "       0.04647958, 0.01455335, 0.02107242, 0.01245102, 0.02008774,\n",
       "       0.00932492, 0.06478948, 0.02849046, 0.05258393, 0.01309683,\n",
       "       0.01511937, 0.0948671 , 0.04245669, 0.01848982, 0.01712147,\n",
       "       0.00964795, 0.01387581, 0.0155663 , 0.02446137, 0.0183479 ,\n",
       "       0.01811038, 0.01236162, 0.0125117 , 0.01217248, 0.01536456,\n",
       "       0.01409171, 0.02672821, 0.01917254, 0.04390707, 0.02620314,\n",
       "       0.01450673, 0.01033344, 0.01303971, 0.01450122, 0.01475502,\n",
       "       0.0158363 , 0.01151279, 0.02440881, 0.00729097, 0.00770893,\n",
       "       0.01238225, 0.02183167, 0.02395606, 0.01736567, 0.01858573,\n",
       "       0.01656156, 0.10327526, 0.02665544, 0.0110118 , 0.02162521,\n",
       "       0.01078671, 0.01474303, 0.01167603, 0.01284415, 0.0147536 ,\n",
       "       0.04031122, 0.02447886, 0.00666857, 0.0103702 , 0.01197431,\n",
       "       0.0158186 , 0.07916632, 0.02757759, 0.00735081, 0.01725691,\n",
       "       0.03208768, 0.04267018, 0.01953672, 0.02481727, 0.01280074,\n",
       "       0.02828601, 0.02917298, 0.01163605, 0.02868423, 0.04733065,\n",
       "       0.01277535, 0.01330288, 0.01434874, 0.01946345, 0.04939595,\n",
       "       0.02266414, 0.02909233, 0.04372662, 0.02537984, 0.01716529,\n",
       "       0.02040144, 0.02089994, 0.01551645, 0.02540615, 0.02041331,\n",
       "       0.01010251, 0.01065358, 0.01330119, 0.01852654, 0.02399164,\n",
       "       0.01702905, 0.01541211, 0.01581955, 0.00917889, 0.02873146,\n",
       "       0.02805786, 0.02950441, 0.02428583, 0.01636882, 0.00984873,\n",
       "       0.02108665, 0.02360589, 0.01422195, 0.03640541, 0.01255584,\n",
       "       0.01036697, 0.02002345, 0.05061399, 0.01402436, 0.00824062,\n",
       "       0.01686555, 0.01823948, 0.0290182 , 0.03366975, 0.03247866,\n",
       "       0.02990614, 0.02870274, 0.0324835 , 0.01735842, 0.01076188,\n",
       "       0.00795172, 0.0494087 , 0.01155838, 0.01705855, 0.0160802 ,\n",
       "       0.01300847, 0.04072837, 0.01059689, 0.01577293, 0.03099726,\n",
       "       0.00897905, 0.04196659, 0.02720811, 0.01328692, 0.04597578,\n",
       "       0.01242804, 0.02151283, 0.02384607, 0.01496301, 0.01552744,\n",
       "       0.01377495, 0.00191356, 0.01869999, 0.02636435, 0.02087841,\n",
       "       0.00495574, 0.01328387, 0.02061475, 0.00977535, 0.01726639,\n",
       "       0.04170911, 0.01853437, 0.03055786, 0.01861104, 0.01539172,\n",
       "       0.01081466, 0.0163847 , 0.04229571, 0.0084918 , 0.00951637,\n",
       "       0.01548767, 0.018777  , 0.07717078, 0.00973428, 0.01655071,\n",
       "       0.01863472, 0.02797349, 0.0087772 , 0.02278739, 0.01753728,\n",
       "       0.02104228, 0.02562593, 0.0266165 , 0.01687851, 0.04834221,\n",
       "       0.01890657, 0.01477396, 0.02148046, 0.06036997, 0.0164964 ,\n",
       "       0.01351053, 0.02261273, 0.02059076, 0.02280077, 0.11062907,\n",
       "       0.01778883, 0.07020575, 0.07548979, 0.16970233, 0.02594256,\n",
       "       0.05045161, 0.13655542, 0.0402286 , 0.01193964, 0.0314902 ,\n",
       "       0.03406714, 0.02606381, 0.01144728, 0.01238872, 0.0165278 ,\n",
       "       0.01032673, 0.01808999, 0.01474945, 0.01025568, 0.03341434,\n",
       "       0.01665247, 0.05571825, 0.01567656, 0.02543694, 0.04687777,\n",
       "       0.01022686, 0.01237468, 0.00777042, 0.02762305, 0.013391  ,\n",
       "       0.03089059, 0.01180472, 0.03133957, 0.0128828 , 0.01868424,\n",
       "       0.01470658, 0.01153622, 0.00926244, 0.02877013, 0.01713895,\n",
       "       0.03004434, 0.08992542, 0.01633022, 0.00851959, 0.01824768,\n",
       "       0.015301  , 0.02366733, 0.07424683, 0.02721002, 0.02126832,\n",
       "       0.01214031, 0.00619274, 0.0171523 , 0.01246343, 0.04181725,\n",
       "       0.00931157, 0.03759802, 0.02101403, 0.01669324, 0.00797185,\n",
       "       0.02043873, 0.1001782 , 0.02850716, 0.01917867, 0.01303626,\n",
       "       0.02553888, 0.01623169, 0.01609368, 0.01394299, 0.00969071,\n",
       "       0.01884587, 0.02662572, 0.02082976, 0.02987277, 0.01178785,\n",
       "       0.01032837, 0.02150463, 0.01059492, 0.0109234 , 0.01288714,\n",
       "       0.01993036, 0.03970236, 0.08253419, 0.00900263, 0.01632266,\n",
       "       0.01088701, 0.01954464, 0.01832368, 0.02422768, 0.0330855 ,\n",
       "       0.02354629, 0.0871178 , 0.01612236, 0.03047721, 0.03877544,\n",
       "       0.05709411, 0.01657757, 0.02600679, 0.03406204, 0.02633897,\n",
       "       0.01333325, 0.02174936, 0.05003966, 0.01334294, 0.00796081,\n",
       "       0.02170964, 0.0806632 , 0.07483329, 0.01377606, 0.01712888])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(svd_model.components_[0].shape)\n",
    "svd_model.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([448, 483, 458, 626, 893])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내림차순 정렬 후 상위 5개의 단어 반환 -> 0번째 토픽과 가장 연관성이 높은 단어 추출\n",
    "svd_model.components_.argsort()[0][::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('just', 0.20887)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vectorizer.get_feature_names_out()[448],svd_model.components_[0][448].round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('just', 0.20887)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf 벡터에서 어휘집의 인덱싱을 통해 0번째 토픽의 상위5개에 해당하는 단어들 확인해보기\n",
    "(vectorizer.get_feature_names_out()[448], svd_model.components_[0][448].round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jewish', 0.01963)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vectorizer.get_feature_names_out()[443], svd_model.components_[0][443].round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 [('just', 0.20887), ('like', 0.20469), ('know', 0.19349), ('people', 0.18318), ('think', 0.1697)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()    # 어휘집 : 1000개의 단어가 저장되어있음\n",
    "\n",
    "for idx, topic in enumerate(svd_model.components_):\n",
    "    sorted_indiced = topic.argsort()[::-1][:5]\n",
    "    print(\"Topic %d\" %(idx+1), [(terms[i], topic[i].round(5))for i in sorted_indiced])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: [('Topic 1', 0.12113), ('Topic 16', 0.11515), ('Topic 11', 0.06132), ('Topic 4', 0.03096), ('Topic 17', 0.01737), ('Topic 15', 0.01291), ('Topic 20', -0.00022), ('Topic 13', -0.00507), ('Topic 8', -0.00887), ('Topic 10', -0.00913), ('Topic 9', -0.01505), ('Topic 12', -0.01545), ('Topic 14', -0.02146)]\n",
      "Document 2: [('Topic 1', 0.18497), ('Topic 5', 0.0606), ('Topic 20', 0.05117), ('Topic 4', 0.04349), ('Topic 6', 0.04149), ('Topic 13', 0.03836), ('Topic 18', 0.0264), ('Topic 19', 0.01761), ('Topic 14', 0.01354), ('Topic 7', -0.00813), ('Topic 12', -0.00956), ('Topic 11', -0.01125), ('Topic 3', -0.01723)]\n",
      "Document 3: [('Topic 16', 0.21279), ('Topic 1', 0.15809), ('Topic 11', 0.09175), ('Topic 10', 0.06153), ('Topic 15', 0.0545), ('Topic 9', 0.02733), ('Topic 8', 0.0212), ('Topic 20', 0.01339), ('Topic 5', 0.00578), ('Topic 7', 0.00563), ('Topic 17', 0.00478), ('Topic 4', -0.01269), ('Topic 6', -0.01598)]\n",
      "Document 4: [('Topic 1', 0.17093), ('Topic 8', 0.11107), ('Topic 4', 0.10798), ('Topic 7', 0.05057), ('Topic 12', 0.04663), ('Topic 3', 0.04335), ('Topic 19', 0.03836), ('Topic 11', 0.03288), ('Topic 13', 0.03041), ('Topic 5', 0.0107), ('Topic 17', 0.00582), ('Topic 10', 0.00291), ('Topic 14', -0.00914)]\n",
      "Document 5: [('Topic 1', 0.19774), ('Topic 16', 0.0956), ('Topic 19', 0.08071), ('Topic 20', 0.07005), ('Topic 17', 0.04416), ('Topic 5', 0.03357), ('Topic 3', 0.02603), ('Topic 18', 0.02003), ('Topic 8', 0.01605), ('Topic 14', 0.01414), ('Topic 12', 0.0046), ('Topic 2', 0.00412), ('Topic 10', -0.01106)]\n",
      "Document 6: [('Topic 1', 0.11903), ('Topic 13', 0.08816), ('Topic 9', 0.07449), ('Topic 19', 0.05128), ('Topic 12', 0.02605), ('Topic 5', 0.0202), ('Topic 6', 0.00944), ('Topic 15', 0.00736), ('Topic 10', -0.00334), ('Topic 4', -0.01019), ('Topic 20', -0.03423), ('Topic 3', -0.04276), ('Topic 17', -0.06028)]\n",
      "Document 7: [('Topic 1', 0.22735), ('Topic 20', 0.12649), ('Topic 9', 0.12144), ('Topic 19', 0.09891), ('Topic 8', 0.08069), ('Topic 16', 0.07916), ('Topic 3', 0.05973), ('Topic 6', 0.05704), ('Topic 2', 0.05293), ('Topic 13', 0.05034), ('Topic 11', 0.04065), ('Topic 17', 0.03381), ('Topic 15', 0.0313)]\n",
      "Document 8: [('Topic 1', 0.21609), ('Topic 10', 0.13428), ('Topic 8', 0.10599), ('Topic 6', 0.06985), ('Topic 5', 0.06981), ('Topic 11', 0.0615), ('Topic 15', 0.05066), ('Topic 9', 0.04706), ('Topic 14', 0.04292), ('Topic 16', 0.04005), ('Topic 7', 0.01701), ('Topic 20', -0.01571), ('Topic 2', -0.044)]\n",
      "Document 9: [('Topic 6', 0.22429), ('Topic 7', 0.20871), ('Topic 1', 0.19671), ('Topic 13', 0.09478), ('Topic 5', 0.05897), ('Topic 4', 0.0516), ('Topic 11', 0.04825), ('Topic 16', 0.02221), ('Topic 17', 0.0205), ('Topic 3', 0.02023), ('Topic 9', 0.01869), ('Topic 10', 0.01691), ('Topic 18', 0.00906)]\n",
      "Document 10: [('Topic 1', 0.24858), ('Topic 7', 0.14867), ('Topic 9', 0.0813), ('Topic 10', 0.04722), ('Topic 5', 0.04705), ('Topic 6', 0.0456), ('Topic 3', 0.04403), ('Topic 17', 0.04148), ('Topic 19', 0.03895), ('Topic 2', 0.02733), ('Topic 16', 0.02295), ('Topic 18', 0.02084), ('Topic 4', 0.01928)]\n"
     ]
    }
   ],
   "source": [
    "# 문서별 가장 관련성이 높은 (비중이 높은) 토픽 상위 n개를 추출하는 함수 생성\n",
    "\n",
    "def get_document_topics(lsa_matrix, n=5):\n",
    "    for idx, doc in enumerate(lsa_matrix):\n",
    "        if idx == 10: break\n",
    "        print(f\"Document {idx+1}:\", [(f\"Topic {i+1}\", doc[i].round(5)) for i in doc.argsort()[::-1][:n]])\n",
    "\n",
    "\n",
    "# 문서벡터 행렬 생성\n",
    "lsa_matrix = svd_model.transform(X)\n",
    "\n",
    "# 문서별 토픽 비율 확인\n",
    "get_document_topics(lsa_matrix, n=13)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+9sQ+qqyTgybw/41whDYm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "sesac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
